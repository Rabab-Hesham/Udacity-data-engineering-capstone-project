{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta, date\n",
    "import pyspark\n",
    "from pyspark.sql.functions import udf, to_date, col, year, month, date_format, format_number, isnull\n",
    "from pyspark.sql.functions import isnan, when, count, col ,udf, monotonically_increasing_id, year, month\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType, StructType\n",
    "from pyspark.sql.types import *\n",
    "import logging\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "- Create a data warehouse using Apache Spark by execute ETL pipeline after cleaning the data, and then write them to parquet files and store them in an output folder.\n",
    "- Star schema will be created that contains 1 fact table and 3 dimension tables.\n",
    "- Another tools will be used tp prepare our data like panadas.\n",
    "- The goal of the project is to analyze the U.S. immigration data regarding several perspectives.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "- I94 Immigration Data: This data comes from the US National Tourism and Trade Office. There's a sample file so you can take a look at the data in csv format before reading it all in. You do not have to use the entire dataset, just use what you need to accomplish the goal you set at the beginning of the project.\n",
    "- World Temperature Data: This dataset came from Kaggle. \n",
    "- U.S. City Demographic Data: This data comes from OpenSoft. \n",
    "- Airport Code Table: This is a simple table of airport codes and corresponding cities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Load Configuration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#config = configparser.ConfigParser()\n",
    "#config.read('config.cfg')\n",
    "\n",
    "#os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "#os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- ### Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_immigration = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_immigration.write.parquet(\"sas_data\")\n",
    "#df_immigration=spark.read.parquet(\"sas_data\")\n",
    "\n",
    "\n",
    "#df_immigration.write.mode('overwrite').parquet(\"sas_data\")\n",
    "#df_immigration=spark.read.parquet(\"sas_data\")\n",
    "#df_immigration.limit(10).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print its head\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3096313, 28)\n"
     ]
    }
   ],
   "source": [
    "print((df_immigration.count(), len(df_immigration.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+-----+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+-------+--------+\n",
      "|summary|  cicid|  i94yr| i94mon| i94cit| i94res|i94port|arrdate|i94mode|i94addr|depdate| i94bir|i94visa|  count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto| gender|insnum|airline| admnum|  fltno|visatype|\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+-----+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+-------+--------+\n",
      "|  count|3096313|3096313|3096313|3096313|3096313|3096313|3096313|3096074|2943721|2953856|3095511|3096313|3096313| 3096312| 1215063| 8126|3096075|2957884|    392|2957884|3095511|3095836|2682044|113708|3012686|3096313|3076764| 3096313|\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+-----+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration.summary(\"count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As shown from the previous code:\n",
    "- some columns' names are not clear enough.\n",
    "- some columns have high missing values (\"visapost\", \"occup\", \"entdepu\" and \"insnum\"). This columns need to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicates\n",
    "df_immigration.distinct().count() == df_immigration.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As shown, the dataset does not have any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cicid', 'double'),\n",
       " ('i94yr', 'double'),\n",
       " ('i94mon', 'double'),\n",
       " ('i94cit', 'double'),\n",
       " ('i94res', 'double'),\n",
       " ('i94port', 'string'),\n",
       " ('arrdate', 'double'),\n",
       " ('i94mode', 'double'),\n",
       " ('i94addr', 'string'),\n",
       " ('depdate', 'double'),\n",
       " ('i94bir', 'double'),\n",
       " ('i94visa', 'double'),\n",
       " ('count', 'double'),\n",
       " ('dtadfile', 'string'),\n",
       " ('visapost', 'string'),\n",
       " ('occup', 'string'),\n",
       " ('entdepa', 'string'),\n",
       " ('entdepd', 'string'),\n",
       " ('entdepu', 'string'),\n",
       " ('matflag', 'string'),\n",
       " ('biryear', 'double'),\n",
       " ('dtaddto', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('insnum', 'string'),\n",
       " ('airline', 'string'),\n",
       " ('admnum', 'double'),\n",
       " ('fltno', 'string'),\n",
       " ('visatype', 'string')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the type of each column\n",
    "df_immigration.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As shown the type of the date should be fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- ### Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read the data\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data's head\n",
    "df_temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Denmark' 'Turkey' 'Kazakhstan' 'China' 'Spain' 'Germany' 'Nigeria' 'Iran'\n",
      " 'Russia' 'Canada' \"Côte D'Ivoire\" 'United Kingdom' 'Saudi Arabia' 'Japan'\n",
      " 'United States' 'India' 'Benin' 'United Arab Emirates' 'Mexico'\n",
      " 'Venezuela' 'Ghana' 'Ethiopia' 'Australia' 'Yemen' 'Indonesia' 'Morocco'\n",
      " 'Pakistan' 'France' 'Libya' 'Burma' 'Brazil' 'South Africa' 'Syria'\n",
      " 'Egypt' 'Algeria' 'Netherlands' 'Malaysia' 'Portugal' 'Ecuador' 'Italy'\n",
      " 'Uzbekistan' 'Philippines' 'Madagascar' 'Chile' 'Belgium' 'El Salvador'\n",
      " 'Romania' 'Peru' 'Colombia' 'Tanzania' 'Tunisia' 'Turkmenistan' 'Israel'\n",
      " 'Eritrea' 'Paraguay' 'Greece' 'New Zealand' 'Vietnam' 'Cameroon' 'Iraq'\n",
      " 'Afghanistan' 'Argentina' 'Azerbaijan' 'Moldova' 'Mali'\n",
      " 'Congo (Democratic Republic Of The)' 'Thailand' 'Central African Republic'\n",
      " 'Bosnia And Herzegovina' 'Bangladesh' 'Switzerland' 'Equatorial Guinea'\n",
      " 'Cuba' 'Lebanon' 'Mozambique' 'Serbia' 'Angola' 'Somalia' 'Norway' 'Nepal'\n",
      " 'Poland' 'Ukraine' 'Guinea Bissau' 'Malawi' 'Burkina Faso' 'Slovakia'\n",
      " 'Congo' 'Belarus' 'Gambia' 'Czech Republic' 'Hungary' 'Burundi' 'Zimbabwe'\n",
      " 'Bulgaria' 'Haiti' 'Puerto Rico' 'Sri Lanka' 'Nicaragua' 'Zambia'\n",
      " 'Honduras' 'Taiwan' 'Bolivia' 'Guinea' 'Ireland' 'Senegal' 'Latvia'\n",
      " 'Qatar' 'Albania' 'Tajikistan' 'Kenya' 'Guatemala' 'Finland'\n",
      " 'Sierra Leone' 'Sweden' 'Botswana' 'Guyana' 'Austria' 'Uganda' 'Armenia'\n",
      " 'Dominican Republic' 'Jordan' 'Djibouti' 'Sudan' 'Lithuania' 'Rwanda'\n",
      " 'Jamaica' 'Togo' 'Macedonia' 'Cyprus' 'Gabon' 'Slovenia' 'Bahrain'\n",
      " 'Swaziland' 'Niger' 'Lesotho' 'Liberia' 'Uruguay' 'Chad' 'Bahamas'\n",
      " 'Mauritania' 'Panama' 'Suriname' 'Cambodia' 'Montenegro' 'Mauritius'\n",
      " 'Papua New Guinea' 'Iceland' 'Croatia' 'Reunion' 'Oman' 'Costa Rica'\n",
      " 'South Korea' 'Hong Kong' 'Singapore' 'Estonia' 'Georgia' 'Mongolia'\n",
      " 'Laos' 'Namibia']\n"
     ]
    }
   ],
   "source": [
    "print(df_temperature['Country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- as shown the dataset has data related to other countaries in countary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8599212, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt                               8599212\n",
      "AverageTemperature               8235082\n",
      "AverageTemperatureUncertainty    8235082\n",
      "City                             8599212\n",
      "Country                          8599212\n",
      "Latitude                         8599212\n",
      "Longitude                        8599212\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_temperature.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- As shown from the previous code some columns have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [dt, AverageTemperature, AverageTemperatureUncertainty, City, Country, Latitude, Longitude]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates\n",
    "duplicateRows = df_temperature[df_temperature.duplicated()]\n",
    "print(duplicateRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- As shown the data does not have any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8599212 entries, 0 to 8599211\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 459.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#print the type of each column\n",
    "df_temperature.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- The type of date time need to be modified to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- ### U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read the data\n",
    "df_demographic = pd.read_csv('us-cities-demographics.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the head of the data\n",
    "df_demographic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City                      2891\n",
      "State                     2891\n",
      "Median Age                2891\n",
      "Male Population           2888\n",
      "Female Population         2888\n",
      "Total Population          2891\n",
      "Number of Veterans        2878\n",
      "Foreign-born              2878\n",
      "Average Household Size    2875\n",
      "State Code                2891\n",
      "Race                      2891\n",
      "Count                     2891\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print the count of data in each column\n",
    "print(df_demographic.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As shown from the previous code some columns have some missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [City, State, Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, State Code, Race, Count]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates\n",
    "duplicateRows = df_demographic[df_demographic.duplicated()]\n",
    "print(duplicateRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As shown the data does not have any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#print the type of each column\n",
    "df_demographic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As shown, all the column types are correctly coded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Drop all the rows that contain other countries than the US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "- ### Immigration Data\n",
    "some columns' names are not clear enough.\n",
    "some columns have high missing values (\"visapost\", \"occup\", \"entdepu\" and \"insnum\"). This columns need to be dropped.\n",
    "Type of the date should be fixed\n",
    "\n",
    "- ### Temperature Data\n",
    "some columns have missing values.\n",
    "The type of date needs to be fixed.\n",
    "The dataset has data related to other countaries in countary column\n",
    "The name of column dt is not clear\n",
    "\n",
    "- ### U.S. City Demographic Data\n",
    "some columns have some missing values.\n",
    "\n",
    "#### Cleaning Steps\n",
    "1- Drop \"visapost\", \"occup\" and \"insnum\" columns in immigration dataset.\n",
    "\n",
    "2- Replace the missing values and nan in other columns with zero\n",
    "\n",
    "3- Convert the type of some columns to integer\n",
    "\n",
    "4- Rename the unclear named columns in immigration dataset.\n",
    "\n",
    "5- change the type of date column to DateTime in immigration dataset.\n",
    "\n",
    "6- Drop the missing data rows in temperature dataset.\n",
    "\n",
    "7- - Drop the rows that has data to other countaries in countary column in temperature dataset.\n",
    "\n",
    "8- Change the type of dt to datetime in temperature dataset.\n",
    "\n",
    "9- Rename the dt column.\n",
    "\n",
    "10- Drop the missing data rows in demographic dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop the rows that have missing values in immigration dataset\n",
    "clean_immigration = df_immigration.drop('visapost', 'occup', 'insnum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count', 'dtadfile', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'airline', 'admnum', 'fltno', 'visatype']\n"
     ]
    }
   ],
   "source": [
    "#check the previous code\n",
    "print(list(clean_immigration.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#replace the missing values and nan in other columns with zero\n",
    "clean_immigration = clean_immigration.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#rename the unclear named columns\n",
    "\n",
    "clean_immigration = clean_immigration.select(['cicid', 'i94yr', 'i94mon', 'i94port', \\\n",
    "                                              'arrdate', 'i94addr', 'depdate']).distinct()\\\n",
    ".withColumnRenamed(\"cicid\",\"cicid\")\\\n",
    ".withColumnRenamed(\"i94yr\",\"year\")\\\n",
    ".withColumnRenamed(\"i94mon\",\"month\")\\\n",
    ".withColumnRenamed(\"i94port\",\"Port_of_admission\")\\\n",
    ".withColumnRenamed(\"arrdate\",\"arrival_date\")\\\n",
    ".withColumnRenamed(\"i94addr\",\"state_code\")\\\n",
    ".withColumnRenamed(\"depdate\",\"departure_date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cicid', 'year', 'month', 'Port_of_admission', 'arrival_date', 'state_code', 'departure_date']\n"
     ]
    }
   ],
   "source": [
    "#check the previous code\n",
    "print(list(clean_immigration.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#convert the type of some columns to integer\n",
    "\n",
    "clean_immigration = clean_immigration.withColumn(\"year\",clean_immigration.year.cast(IntegerType()))\\\n",
    "                  .withColumn(\"month\",clean_immigration.month.cast(IntegerType()))\\\n",
    "                  .withColumn(\"arrival_date\",clean_immigration.arrival_date.cast(IntegerType()))\\\n",
    "                  .withColumn(\"departure_date\",clean_immigration.departure_date.cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cicid', 'double'), ('year', 'int'), ('month', 'int'), ('Port_of_admission', 'string'), ('arrival_date', 'int'), ('state_code', 'string'), ('departure_date', 'int')]\n"
     ]
    }
   ],
   "source": [
    "#check the previous code\n",
    "print(clean_immigration.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>Port_of_admission</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>state_code</th>\n",
       "      <th>departure_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545</td>\n",
       "      <td>MD</td>\n",
       "      <td>20554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20545</td>\n",
       "      <td>FL</td>\n",
       "      <td>20559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>596.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>NAS</td>\n",
       "      <td>20545</td>\n",
       "      <td>FL</td>\n",
       "      <td>20547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>790.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20545</td>\n",
       "      <td>FL</td>\n",
       "      <td>20559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1112.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20545</td>\n",
       "      <td>NY</td>\n",
       "      <td>20554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cicid  year  month Port_of_admission  arrival_date state_code  \\\n",
       "0   181.0  2016      4               WAS         20545         MD   \n",
       "1   394.0  2016      4               MIA         20545         FL   \n",
       "2   596.0  2016      4               NAS         20545         FL   \n",
       "3   790.0  2016      4               ATL         20545         FL   \n",
       "4  1112.0  2016      4               NEW         20545         NY   \n",
       "\n",
       "   departure_date  \n",
       "0           20554  \n",
       "1           20559  \n",
       "2           20547  \n",
       "3           20559  \n",
       "4           20554  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#drop the missing data rows\n",
    "clean_temperature = df_temperature.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt                               8235082\n",
      "AverageTemperature               8235082\n",
      "AverageTemperatureUncertainty    8235082\n",
      "City                             8235082\n",
      "Country                          8235082\n",
      "Latitude                         8235082\n",
      "Longitude                        8235082\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(clean_temperature.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#drop other data related to other countaries but United States\n",
    "clean_temperature = clean_temperature.loc[clean_temperature['Country'] == 'United States'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States']\n"
     ]
    }
   ],
   "source": [
    "#check the previous code\n",
    "print(clean_temperature['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#change the type of dt to datetime\n",
    "clean_temperature['dt']= pd.to_datetime(clean_temperature['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 661524 entries, 47555 to 8439246\n",
      "Data columns (total 7 columns):\n",
      "dt                               661524 non-null datetime64[ns]\n",
      "AverageTemperature               661524 non-null float64\n",
      "AverageTemperatureUncertainty    661524 non-null float64\n",
      "City                             661524 non-null object\n",
      "Country                          661524 non-null object\n",
      "Latitude                         661524 non-null object\n",
      "Longitude                        661524 non-null object\n",
      "dtypes: datetime64[ns](1), float64(2), object(4)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#check the previous code\n",
    "clean_temperature.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_time</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date_time  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555 1820-01-01               2.101                          3.217  Abilene   \n",
       "47556 1820-02-01               6.926                          2.853  Abilene   \n",
       "47557 1820-03-01              10.767                          2.395  Abilene   \n",
       "47558 1820-04-01              17.989                          2.202  Abilene   \n",
       "47559 1820-05-01              21.809                          2.036  Abilene   \n",
       "\n",
       "             Country Latitude Longitude  \n",
       "47555  United States   32.95N   100.53W  \n",
       "47556  United States   32.95N   100.53W  \n",
       "47557  United States   32.95N   100.53W  \n",
       "47558  United States   32.95N   100.53W  \n",
       "47559  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename the dt column\n",
    "clean_temperature = clean_temperature[['dt', 'AverageTemperature', 'AverageTemperatureUncertainty', 'City', 'Country', 'Latitude', 'Longitude']]\n",
    "clean_temperature.columns = ['Date_time', 'AverageTemperature', 'AverageTemperatureUncertainty', 'City', 'Country', 'Latitude', 'Longitude']\n",
    "clean_temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#drop the missing data rows\n",
    "clean_demographic = df_demographic.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City                      2875\n",
      "State                     2875\n",
      "Median Age                2875\n",
      "Male Population           2875\n",
      "Female Population         2875\n",
      "Total Population          2875\n",
      "Number of Veterans        2875\n",
      "Foreign-born              2875\n",
      "Average Household Size    2875\n",
      "State Code                2875\n",
      "Race                      2875\n",
      "Count                     2875\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check the previous code\n",
    "print(clean_demographic.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "1- fact table\n",
    "\n",
    "cicid --> Unique identifier\n",
    "\n",
    "i94yr --> year\n",
    "\n",
    "i94mon --> month\n",
    "\n",
    "i94port --> Port_of_admission\n",
    "\n",
    "arrdate --> arrival_date\n",
    "\n",
    "i94addr --> state_code\n",
    "\n",
    "depdate --> departure_date\n",
    "\n",
    "\n",
    "# Dimension tables\n",
    "\n",
    "1- dim_visa\n",
    "\n",
    "cicid --> Unique identifier\n",
    "\n",
    "i94mode --> mode of transportation\n",
    "\n",
    "i94visa --> visa\n",
    "\n",
    "airline --> airline\n",
    "\n",
    "fltno --> flight number\n",
    "\n",
    "visatype --> visa type\n",
    "\n",
    "\n",
    "2- dim_flag\n",
    "\n",
    "cicid --> Unique identifier\n",
    "\n",
    "entdepa --> Arrival_Flag\n",
    "\n",
    "entdepd --> Departure_Flag\n",
    "\n",
    "entdepu --> Update_Flag\n",
    "\n",
    "matflag --> Match_Flag\n",
    "\n",
    "3- dim_immigrant\n",
    "\n",
    "cicid --> Unique identifier\n",
    "\n",
    "i94cit --> citizenship_code\n",
    "\n",
    "i94res --> residence_code\n",
    "\n",
    "i94bir -->  birthday\n",
    "\n",
    "biryear --> birthday_year\n",
    "\n",
    "gender --> gender\n",
    "\n",
    "4- dim_city : City ,State, State_Code, Race\n",
    "\n",
    "5- dim_Population : Median_Age, Male_Population, Female_Population, Total_Population, Number_of_Veterans, Foreign_born'\n",
    "       Average_Household_Size, State_Code, Race\n",
    "       \n",
    "6- dim_temperature: dt (date time), Average Temperature, Average Temperature Uncertainty, City, Country\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "- Upload the datasets and follow the cleaning steps then parquet them using spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "1- create IAM user on AWS and add the secret and access keys in dl.cfg\n",
    " \n",
    "2- create EMR cluster on AWS and edit the output path in etl.py\n",
    "    \n",
    "3- run etl.py file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read the created tables in spark\n",
    "dim_city = spark.read.csv('dim_city')\n",
    "dim_flag = spark.read.csv('dim_flag')\n",
    "dim_immigrant = spark.read.csv('dim_immigrant')\n",
    "dim_Population = spark.read.csv('dim_Population')\n",
    "dim_temperature = spark.read.csv('dim_temperature')\n",
    "fact_immigration = spark.read.csv('fact_immigration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#lis the tables and the table names\n",
    "table = ['dim_city', 'dim_flag', 'dim_immigrant', 'dim_Population', 'dim_temperature', 'fact_immigration']\n",
    "table_name = ['dim_city', 'dim_flag', 'dim_immigrant', 'dim_Population', 'dim_temperature', 'fact_immigration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dim_city\n",
      "dim_city table has 2892 rows\n",
      "None\n",
      "Checking dim_flag\n",
      "dim_flag table has 236 rows\n",
      "None\n",
      "Checking dim_immigrant\n",
      "dim_immigrant table has 2681244 rows\n",
      "None\n",
      "Checking dim_Population\n",
      "dim_Population table has 2876 rows\n",
      "None\n",
      "Checking dim_temperature\n",
      "dim_temperature table has 661525 rows\n",
      "None\n",
      "Checking fact_immigration\n",
      "fact_immigration table has 2817745 rows\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#first quality check: check whether there is an empty table or not.\n",
    "\n",
    "def quality_check(table, table_name):\n",
    "    print(f'Checking {table_name}')\n",
    "    rows_num = table.count()\n",
    "    if rows_num == 0:\n",
    "        raise ValueError(f'{table_name} table has no rows')\n",
    "    print(f'{table_name} table has {rows_num} rows')\n",
    "print(quality_check(dim_city, \"dim_city\"))\n",
    "print(quality_check(dim_flag, \"dim_flag\"))\n",
    "print(quality_check(dim_immigrant, \"dim_immigrant\"))\n",
    "print(quality_check(dim_Population, \"dim_Population\"))\n",
    "print(quality_check(dim_temperature, \"dim_temperature\"))\n",
    "print(quality_check(fact_immigration, \"fact_immigration\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_city doesn't have duplicates\n",
      "None\n",
      "dim_flag doesn't have duplicates\n",
      "None\n",
      "dim_immigrant doesn't have duplicates\n",
      "None\n",
      "dim_Population doesn't have duplicates\n",
      "None\n",
      "dim_temperature doesn't have duplicates\n",
      "None\n",
      "fact_immigration doesn't have duplicates\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#quality check 2: check whether there is a duplicates in the tables or not.\n",
    "\n",
    "def quality_check_2 (table, table_name):\n",
    "    duplicates = table.distinct().count() == table.count()\n",
    "    if duplicates != True:\n",
    "        raise ValueError(f'{table_name} table has duplicates')\n",
    "    print(f'{table_name} doesn\\'t have duplicates')\n",
    "    \n",
    "print(quality_check_2(dim_city, \"dim_city\"))\n",
    "print(quality_check_2(dim_flag, \"dim_flag\"))\n",
    "print(quality_check_2(dim_immigrant, \"dim_immigrant\"))\n",
    "print(quality_check_2(dim_Population, \"dim_Population\"))\n",
    "print(quality_check_2(dim_temperature, \"dim_temperature\"))\n",
    "print(quality_check_2(fact_immigration, \"fact_immigration\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "kindly check the Data dictionary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: \n",
    "\n",
    "# Tools:\n",
    "\n",
    "- Use Spark to process the data efficiently in a distributed way with EMR. \n",
    "- pandas would be helpful in cleaning the data and faster\n",
    "- Parquet Columnar storage and partitioning of our data allows us to optimize queries for analysis.\n",
    "\n",
    "# Updating the data:\n",
    "\n",
    "Since the fact table was extracted from immigration data as well as 3 dimension tables, I recommend updating the data monthly to be current.\n",
    "\n",
    "# Hypothetical Scenarios:\n",
    "\n",
    "- Increase the size of the data by 100 times: In this case, I recommend increasing the number of the nodes.\n",
    "\n",
    "- The data fills a dashboard that needs to be updated daily by 7am:\n",
    "In this case, it is more helpful to create a DAG and use Airflow.\n",
    "\n",
    "- The database needs to be accessed by more than 100 people: AWS is definitely the ideal solution in this case.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
